#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIä»£ç å®‰å…¨å®¡è®¡CLIå·¥å…· - å¢å¼ºç‰ˆä¸»ç¨‹åº
é›†æˆä¾èµ–æ³¨å…¥ã€é…ç½®ç®¡ç†ã€ç¼“å­˜ã€è¿›åº¦æ˜¾ç¤ºç­‰é«˜çº§åŠŸèƒ½
"""

import asyncio
import argparse
import logging
import sys
import os
from pathlib import Path
from typing import List, Optional, Dict, Any

# è®¾ç½®æ§åˆ¶å°ç¼–ç 
import io
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))
from src.core.container import get_container, initialize_container, cleanup_container
from src.core.interfaces import (
    ICodeAnalyzer, IReportGenerator, IConfigManager, ICacheManager,
    IProgressReporter, IErrorHandler, SeverityLevel, AppConfig, AnalysisResult
)
from src.core.analyzers.base_analyzer import BaseCodeAnalyzer
from src.infrastructure.progress_reporter import ProgressReporterFactory
from src.infrastructure.error_handler import create_error_handler
from src.application.report_generators import ReportGeneratorFactory
from src.infrastructure.ui_manager import UIManager, show_startup_banner, show_loading, clear_terminal
from src.infrastructure.ascii_art import CODESENTINEL_LOGO, SIMPLE_LOGO, STATUS_ICONS, create_gradient_text


# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('security_audit.log', encoding='utf-8')
    ]
)

logger = logging.getLogger(__name__)


class SecurityAuditCLI:
    """å¢å¼ºç‰ˆå®‰å…¨å®¡è®¡CLIå·¥å…·"""

    def __init__(self):
        self.container = get_container()
        self.config_manager: Optional[IConfigManager] = None
        self.cache_manager: Optional[ICacheManager] = None
        self.progress_reporter: Optional[IProgressReporter] = None
        self.error_handler: Optional[IErrorHandler] = None
        self.app_config: Optional[AppConfig] = None

    async def initialize(self, config_path: Optional[str] = None) -> bool:
        """åˆå§‹åŒ–åº”ç”¨ç¨‹åº"""
        try:
            logger.info("æ­£åœ¨åˆå§‹åŒ–å®‰å…¨å®¡è®¡å·¥å…·...")

            # åŠ è½½é…ç½®
            await self._load_configuration(config_path)

            # åˆå§‹åŒ–ä¾èµ–æ³¨å…¥å®¹å™¨
            await initialize_container(self.app_config)

            # è·å–ç»„ä»¶å®ä¾‹
            self.config_manager = self.container.resolve(IConfigManager)
            self.cache_manager = self.container.resolve(ICacheManager)
            self.error_handler = self.container.resolve(IErrorHandler)

            logger.info("âœ… åº”ç”¨ç¨‹åºåˆå§‹åŒ–æˆåŠŸ")
            return True

        except Exception as e:
            logger.error(f"âŒ åº”ç”¨ç¨‹åºåˆå§‹åŒ–å¤±è´¥: {e}")
            if self.error_handler:
                error_info = self.error_handler.handle_error(e, {"phase": "initialization"})
                self._display_error_info(error_info)
            return False

    async def _load_configuration(self, config_path: Optional[str] = None) -> None:
        """åŠ è½½é…ç½®"""
        try:
            # åˆ›å»ºé…ç½®ç®¡ç†å™¨
            if not self.container.is_registered(IConfigManager):
                from src.infrastructure.config_manager import JsonConfigManager
                self.container.register(IConfigManager, JsonConfigManager())
            self.config_manager = self.container.resolve(IConfigManager)

            # åŠ è½½é…ç½®
            config_dict = await self.config_manager.load_config(config_path)
            self.app_config = AppConfig(**config_dict)

            logger.info(f"é…ç½®åŠ è½½æˆåŠŸ: {config_path or 'é»˜è®¤é…ç½®'}")

        except Exception as e:
            logger.warning(f"é…ç½®åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
            self.app_config = AppConfig()

    def _create_argument_parser(self) -> argparse.ArgumentParser:
        """åˆ›å»ºå‚æ•°è§£æå™¨"""
        parser = argparse.ArgumentParser(
            description="AIä»£ç å®‰å…¨å®¡è®¡CLIå·¥å…· v1.0 - æ™ºèƒ½æ£€æµ‹ä»£ç å®‰å…¨æ¼æ´",
            formatter_class=argparse.RawDescriptionHelpFormatter,
            epilog="""
ç¤ºä¾‹ç”¨æ³•:
  %(prog)s script.py                          # åˆ†æå•ä¸ªPythonæ–‡ä»¶
  %(prog)s app.js                             # åˆ†æå•ä¸ªJavaScriptæ–‡ä»¶
  %(prog)s src/                              # åˆ†ææ•´ä¸ªç›®å½•ï¼ˆæ”¯æŒå¤šè¯­è¨€ï¼‰
  %(prog)s app.py --output report.md         # å¯¼å‡ºMarkdownæŠ¥å‘Š
  %(prog)s *.js --format json --output result.json  # å¯¼å‡ºJSONæŠ¥å‘Š
  %(prog)s code/ --config custom.json        # ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
  %(prog)s test.py --analyzer local          # ä½¿ç”¨æœ¬åœ°åˆ†æå™¨
  %(prog)s src/ --analyzer multi_language    # ä½¿ç”¨å¤šè¯­è¨€åˆ†æå™¨
  %(prog)s src/ --progress --verbose         # æ˜¾ç¤ºè¿›åº¦å’Œè¯¦ç»†ä¿¡æ¯
            """
        )

        # ä½ç½®å‚æ•° - æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„
        parser.add_argument(
            'paths',
            nargs='+',
            help='è¦åˆ†æçš„æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„ï¼ˆæ”¯æŒPythonå’ŒJavaScriptï¼‰'
        )

        # åŸºæœ¬é€‰é¡¹
        parser.add_argument(
            '-o', '--output',
            type=str,
            help='è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„'
        )

        parser.add_argument(
            '-f', '--format',
            choices=['console', 'markdown', 'json', 'html', 'xml'],
            default='console',
            help='è¾“å‡ºæ ¼å¼ï¼ˆé»˜è®¤ï¼šconsoleï¼‰'
        )

        parser.add_argument(
            '--analyzer',
            choices=['local', 'ai', 'hybrid', 'multi_language'],
            default='multi_language',
            help='åˆ†æå™¨ç±»å‹ï¼ˆé»˜è®¤ï¼šmulti_languageï¼‰'
        )

        parser.add_argument(
            '--severity',
            choices=['low', 'medium', 'high', 'critical', 'all'],
            default='all',
            help='æœ€ä½æ¼æ´ä¸¥é‡ç¨‹åº¦ï¼ˆé»˜è®¤ï¼šallï¼‰'
        )

        # é«˜çº§é€‰é¡¹
        parser.add_argument(
            '--config',
            type=str,
            help='é…ç½®æ–‡ä»¶è·¯å¾„'
        )

        parser.add_argument(
            '--max-file-size',
            type=int,
            default=1024,
            help='æœ€å¤§æ–‡ä»¶å¤§å°é™åˆ¶ï¼ˆKBï¼Œé»˜è®¤ï¼š1024ï¼‰'
        )

        parser.add_argument(
            '--exclude',
            nargs='+',
            default=[],
            help='æ’é™¤çš„æ–‡ä»¶æˆ–ç›®å½•æ¨¡å¼ï¼ˆå¦‚ï¼štest_*.py, __pycache__ï¼‰'
        )

        parser.add_argument(
            '--include',
            nargs='+',
            default=['*.py', '*.js', '*.jsx', '*.mjs', '*.cjs'],
            help='åŒ…å«çš„æ–‡ä»¶æ¨¡å¼ï¼ˆå¦‚ï¼š*.py, *.js, *.jsxç­‰ï¼‰'
        )

        # ç¼“å­˜é€‰é¡¹
        parser.add_argument(
            '--no-cache',
            action='store_true',
            help='ç¦ç”¨ç¼“å­˜æœºåˆ¶'
        )

        parser.add_argument(
            '--clear-cache',
            action='store_true',
            help='æ¸…é™¤ç¼“å­˜åé€€å‡º'
        )

        # å¹¶å‘é€‰é¡¹
        parser.add_argument(
            '--workers',
            type=int,
            default=None,
            help='å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°ï¼ˆé»˜è®¤ï¼šè‡ªåŠ¨ï¼‰'
        )

        # æ˜¾ç¤ºé€‰é¡¹
        parser.add_argument(
            '--progress',
            action='store_true',
            help='æ˜¾ç¤ºè¿›åº¦æ¡'
        )

        parser.add_argument(
            '--verbose', '-v',
            action='store_true',
            help='æ˜¾ç¤ºè¯¦ç»†è¾“å‡º'
        )

        parser.add_argument(
            '--quiet', '-q',
            action='store_true',
            help='é™é»˜æ¨¡å¼ï¼Œåªæ˜¾ç¤ºé”™è¯¯'
        )

        # éšç§é€‰é¡¹
        parser.add_argument(
            '--privacy-mode',
            choices=['none', 'basic', 'full'],
            default='basic',
            help='éšç§æ¨¡å¼ï¼ˆé»˜è®¤ï¼šbasicï¼‰'
        )

        # å…¶ä»–é€‰é¡¹
        parser.add_argument(
            '--version',
            action='version',
            version='%(prog)s 1.0.0'
        )

        return parser

    async def run_analysis(self, args: argparse.Namespace) -> bool:
        """è¿è¡Œå®‰å…¨åˆ†æ"""
        try:
            logger.info("ğŸš€ å¼€å§‹å®‰å…¨åˆ†æ...")

            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…é™¤ç¼“å­˜
            if args.clear_cache:
                await self._clear_cache()
                return True

            # è®¾ç½®è¿›åº¦æŠ¥å‘Šå™¨
            if args.progress:
                self.progress_reporter = ProgressReporterFactory.create_reporter("tqdm")
            else:
                self.progress_reporter = ProgressReporterFactory.create_reporter("silent")

            # æ”¶é›†æ–‡ä»¶
            files = await self._collect_files(args)
            if not files:
                logger.warning("âš ï¸  æœªæ‰¾åˆ°éœ€è¦åˆ†æçš„æ–‡ä»¶")
                return False

            # è®¾ç½®å¹¶å‘é™åˆ¶
            concurrent_limit = args.workers or self.app_config.analyzer.concurrent_limit

            # è¿è¡Œåˆ†æ
            results = await self._analyze_files(
                files, args, concurrent_limit
            )

            # ç”ŸæˆæŠ¥å‘Š
            await self._generate_reports(results, args)

            logger.info("âœ… å®‰å…¨åˆ†æå®Œæˆ")
            return True

        except Exception as e:
            logger.error(f"âŒ å®‰å…¨åˆ†æå¤±è´¥: {e}")
            if self.error_handler:
                context = {
                    "phase": "analysis",
                    "args": vars(args),
                    "debug_mode": args.verbose
                }
                error_info = self.error_handler.handle_error(e, context)
                self._display_error_info(error_info)
            return False

    async def _collect_files(self, args: argparse.Namespace) -> List[Path]:
        """æ”¶é›†éœ€è¦åˆ†æçš„æ–‡ä»¶"""
        try:
            if args.verbose:
                logger.info("ğŸ“ æ­£åœ¨æ”¶é›†ä»£ç æ–‡ä»¶...")

            all_files = []
            exclude_patterns = args.exclude or self.app_config.security.blocked_patterns
            include_patterns = args.include
            max_file_size = args.max_file_size * 1024  # è½¬æ¢ä¸ºå­—èŠ‚

            for path_str in args.paths:
                path = Path(path_str)

                if not path.exists():
                    logger.warning(f"âš ï¸  è·¯å¾„ä¸å­˜åœ¨: {path}")
                    continue

                if path.is_file():
                    # å•ä¸ªæ–‡ä»¶
                    if self._should_include_file(path, include_patterns, exclude_patterns, max_file_size):
                        all_files.append(path)
                elif path.is_dir():
                    # ç›®å½• - é€’å½’æŸ¥æ‰¾
                    for pattern in include_patterns:
                        for file_path in path.rglob(pattern):
                            if self._should_include_file(file_path, include_patterns, exclude_patterns, max_file_size):
                                all_files.append(file_path)

            if args.verbose:
                logger.info(f"ğŸ“Š æ‰¾åˆ° {len(all_files)} ä¸ªä»£ç æ–‡ä»¶")

            return all_files

        except Exception as e:
            logger.error(f"æ–‡ä»¶æ”¶é›†å¤±è´¥: {e}")
            raise

    def _should_include_file(self, file_path: Path, include_patterns: List[str],
                           exclude_patterns: List[str], max_size: int) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥åŒ…å«è¯¥æ–‡ä»¶"""
        try:
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            if file_path.stat().st_size > max_size:
                logger.debug(f"æ–‡ä»¶è¿‡å¤§ï¼Œå·²è·³è¿‡: {file_path}")
                return False

            # æ£€æŸ¥æ’é™¤æ¨¡å¼
            file_str = str(file_path)
            for pattern in exclude_patterns:
                if self._match_pattern(file_str, pattern):
                    return False

            # æ£€æŸ¥åŒ…å«æ¨¡å¼
            for pattern in include_patterns:
                if self._match_pattern(file_str, pattern):
                    return True

            return False

        except Exception:
            return False

    def _match_pattern(self, text: str, pattern: str) -> bool:
        """ç®€å•çš„æ¨¡å¼åŒ¹é…ï¼ˆæ”¯æŒ*å’Œ?é€šé…ç¬¦ï¼‰"""
        import fnmatch
        return fnmatch.fnmatch(text.lower(), pattern.lower())

    async def _analyze_files(self, files: List[Path], args: argparse.Namespace,
                           concurrent_limit: int) -> Dict[str, Any]:
        """åˆ†ææ–‡ä»¶"""
        try:
            # è·å–åˆ†æå™¨
            analyzer = self.container.resolve(ICodeAnalyzer, args.analyzer)
            severity_filter = self._parse_severity_level(args.severity)

            # å¼€å§‹è¿›åº¦æŠ¥å‘Š
            if self.progress_reporter:
                self.progress_reporter.start_progress(len(files), "ä»£ç å®‰å…¨åˆ†æ")

            # å¢é‡åˆ†æ - æ£€æŸ¥ç¼“å­˜
            if self.cache_manager and not args.no_cache:
                files_to_analyze = await self._filter_cached_files(files)
            else:
                files_to_analyze = files

            if len(files_to_analyze) < len(files):
                logger.info(f"è·³è¿‡ {len(files) - len(files_to_analyze)} ä¸ªå·²ç¼“å­˜æ–‡ä»¶")

            # å¹¶å‘åˆ†æ
            semaphore = asyncio.Semaphore(concurrent_limit)

            async def analyze_with_progress(file_path: Path) -> Dict[str, Any]:
                async with semaphore:
                    result = await analyzer.analyze_file(file_path, severity_filter)

                    # ç¼“å­˜ç»“æœ
                    if self.cache_manager and not args.no_cache:
                        file_hash = self._calculate_file_hash(file_path)
                        self.cache_manager.cache_result(file_hash, result)

                    # æ›´æ–°è¿›åº¦
                    if self.progress_reporter:
                        self.progress_reporter.increment(1, f"åˆ†æå®Œæˆ: {file_path.name}")

                    return result

            # åˆ†ææ‰€æœ‰æ–‡ä»¶
            if files_to_analyze:
                tasks = [analyze_with_progress(fp) for fp in files_to_analyze]
                analysis_results = await asyncio.gather(*tasks, return_exceptions=True)
            else:
                analysis_results = []

            # è·å–ç¼“å­˜çš„ç»“æœ
            cached_results = []
            if self.cache_manager and not args.no_cache:
                for file_path in files:
                    if file_path not in files_to_analyze:
                        file_hash = self._calculate_file_hash(file_path)
                        cached_result = self.cache_manager.get_cached_result(file_hash)
                        if cached_result:
                            cached_results.append(cached_result)
                            if self.progress_reporter:
                                self.progress_reporter.increment(1, f"ä½¿ç”¨ç¼“å­˜: {file_path.name}")

            # åˆå¹¶ç»“æœ
            all_results = []
            for result in analysis_results:
                if isinstance(result, Exception):
                    # å¤„ç†åˆ†æå¼‚å¸¸
                    logger.warning(f"æ–‡ä»¶åˆ†æå¼‚å¸¸: {result}")
                    continue
                all_results.append(result)

            all_results.extend(cached_results)

            # å®Œæˆè¿›åº¦
            if self.progress_reporter:
                self.progress_reporter.finish_progress()

            # æ„å»ºæœ€ç»ˆç»“æœ
            return self._build_analysis_results(all_results, files, args)

        except Exception as e:
            logger.error(f"æ–‡ä»¶åˆ†æå¤±è´¥: {e}")
            raise

    def _parse_severity_level(self, severity_str: str) -> SeverityLevel:
        """è§£æä¸¥é‡åº¦çº§åˆ«"""
        severity_map = {
            'critical': SeverityLevel.CRITICAL,
            'high': SeverityLevel.HIGH,
            'medium': SeverityLevel.MEDIUM,
            'low': SeverityLevel.LOW,
            'all': SeverityLevel.LOW
        }
        return severity_map.get(severity_str, SeverityLevel.LOW)

    async def _filter_cached_files(self, files: List[Path]) -> List[Path]:
        """è¿‡æ»¤å·²ç¼“å­˜çš„æ–‡ä»¶"""
        files_to_analyze = []

        for file_path in files:
            file_hash = self._calculate_file_hash(file_path)
            if not self.cache_manager.is_cache_valid(file_path, file_hash):
                files_to_analyze.append(file_path)

        return files_to_analyze

    def _calculate_file_hash(self, file_path: Path) -> str:
        """è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼ - ä½¿ç”¨SHA-256ç®—æ³•"""
        import hashlib
        try:
            with open(file_path, 'rb') as f:
                file_hash = hashlib.sha256()  # ä»MD5å‡çº§ä¸ºSHA-256
                while chunk := f.read(8192):
                    file_hash.update(chunk)
                return file_hash.hexdigest()
        except Exception:
            return ""

    def _build_analysis_results(self, results: List[AnalysisResult],
                              files: List[Path], args: argparse.Namespace) -> Dict[str, Any]:
        """æ„å»ºåˆ†æç»“æœ"""
        total_vulnerabilities = sum(len(r.vulnerabilities) for r in results)
        files_with_issues = sum(1 for r in results if r.vulnerabilities)

        # ç»Ÿè®¡å„ä¸¥é‡åº¦æ•°é‡
        severity_counts = {'critical': 0, 'high': 0, 'medium': 0, 'low': 0}
        for result in results:
            for vuln in result.vulnerabilities:
                severity = vuln.severity.value
                if severity in severity_counts:
                    severity_counts[severity] += 1

        return {
            'scan_summary': {
                'total_files': len(files),
                'scan_time': 0,  # å°†åœ¨å¤–å±‚è®¡ç®—
                'total_vulnerabilities': total_vulnerabilities,
                'severity_counts': severity_counts,
                'files_with_issues': files_with_issues,
                'analysis_engine': args.analyzer
            },
            'file_results': results
        }

    async def _generate_reports(self, results: Dict[str, Any], args: argparse.Namespace) -> None:
        """ç”ŸæˆæŠ¥å‘Š"""
        try:
            logger.debug(f"å¼€å§‹ç”ŸæˆæŠ¥å‘Š - æ ¼å¼: {args.format}, è¾“å‡º: {args.output}")
            logger.debug(f"åˆ†æç»“æœ: {results}")

            # è·å–æŠ¥å‘Šç”Ÿæˆå™¨
            report_generator = ReportGeneratorFactory.create_report_generator(args.format)
            logger.debug(f"æŠ¥å‘Šç”Ÿæˆå™¨åˆ›å»ºæˆåŠŸ: {type(report_generator)}")

            if args.output:
                # ç”Ÿæˆæ–‡ä»¶æŠ¥å‘Š
                logger.debug(f"ç”Ÿæˆæ–‡ä»¶æŠ¥å‘Šåˆ°: {args.output}")
                report_generator.generate_report(results, args.output)
                logger.info(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {args.output}")
                logger.debug(f"æ–‡ä»¶æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
            else:
                # æ§åˆ¶å°è¾“å‡º
                logger.debug("ç”Ÿæˆæ§åˆ¶å°æŠ¥å‘Š")
                if args.format == 'console':
                    logger.debug("è°ƒç”¨ generate_report")
                    report_generator.generate_report(results)
                    logger.debug("æ§åˆ¶å°æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
                else:
                    # å¯¹äºéæ§åˆ¶å°æ ¼å¼ï¼Œé»˜è®¤è¾“å‡ºåˆ°æ ‡å‡†è¾“å‡º
                    print(f"# å®‰å…¨å®¡è®¡æŠ¥å‘Š ({args.format}æ ¼å¼)")
                    print(f"ç”Ÿæˆæ—¶é—´: {results.get('scan_summary', {}).get('scan_time', 0)}ç§’")
                    print(f"å‘ç°æ¼æ´: {results.get('scan_summary', {}).get('total_vulnerabilities', 0)}ä¸ª")

        except Exception as e:
            logger.error(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            raise

    async def _clear_cache(self) -> None:
        """æ¸…é™¤ç¼“å­˜"""
        try:
            if self.cache_manager:
                logger.info("ğŸ—‘ï¸  æ­£åœ¨æ¸…é™¤ç¼“å­˜...")
                self.cache_manager.clear_cache()
                cleaned_count = self.cache_manager.cleanup_expired_cache()
                logger.info(f"âœ… ç¼“å­˜æ¸…é™¤å®Œæˆï¼Œæ¸…ç†äº† {cleaned_count} ä¸ªè¿‡æœŸæ–‡ä»¶")
            else:
                logger.warning("ç¼“å­˜ç®¡ç†å™¨æœªåˆå§‹åŒ–")
        except Exception as e:
            logger.error(f"æ¸…é™¤ç¼“å­˜å¤±è´¥: {e}")

    def _display_error_info(self, error_info: Dict[str, Any]) -> None:
        """æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯"""
        print(f"\nâŒ é”™è¯¯ç±»å‹: {error_info['error_type']}")
        print(f"âŒ é”™è¯¯ä¿¡æ¯: {error_info['error_message']}")
        print(f"â„¹ï¸  å‹å¥½æç¤º: {error_info['friendly_message']}")
        print(f"ğŸ†” é”™è¯¯ID: {error_info['error_id']}")

        if error_info['suggestions']:
            print("\nğŸ’¡ è§£å†³å»ºè®®:")
            for i, suggestion in enumerate(error_info['suggestions'], 1):
                print(f"   {i}. {suggestion}")

        if error_info.get('technical_details') and error_info['context'].get('debug_mode'):
            print("\nğŸ”§ æŠ€æœ¯è¯¦æƒ…:")
            print(error_info['technical_details']['traceback'])

    async def cleanup(self) -> None:
        """æ¸…ç†èµ„æº"""
        try:
            logger.info("æ­£åœ¨æ¸…ç†èµ„æº...")
            cleanup_container()
            logger.info("âœ… èµ„æºæ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.error(f"èµ„æºæ¸…ç†å¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    # æ˜¾ç¤ºå¯åŠ¨ç•Œé¢
    ui_manager = UIManager()

    # æ¸…å±å¹¶æ˜¾ç¤ºå¯åŠ¨ç•Œé¢
    clear_terminal()
    ui_manager.show_startup_screen("1.0.0")

    # æ˜¾ç¤ºLogoåŠ¨ç”»
    ui_manager.show_logo_animation()

    # æ˜¾ç¤ºåŠ è½½åŠ¨ç”»
    ui_manager.show_loading_animation("Initializing Security Engine", 2.0)

    cli = SecurityAuditCLI()

    try:
        # è§£æå‚æ•°
        parser = cli._create_argument_parser()
        args = parser.parse_args()

        # å¤„ç†é™é»˜æ¨¡å¼
        if args.quiet:
            logging.getLogger().setLevel(logging.ERROR)
        elif args.verbose:
            logging.getLogger().setLevel(logging.DEBUG)

        # åˆå§‹åŒ–
        ui_manager.show_loading_animation("Loading Configuration", 1.0)
        if not await cli.initialize(args.config):
            sys.exit(1)

        # è¿è¡Œåˆ†æ
        ui_manager.show_loading_animation("Starting Security Analysis", 1.0)
        success = await cli.run_analysis(args)

        # é€€å‡º
        sys.exit(0 if success else 1)

    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)

    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œé”™è¯¯: {e}")
        sys.exit(1)

    finally:
        await cli.cleanup()


if __name__ == '__main__':
    # åŠ è½½ç¯å¢ƒå˜é‡
    from dotenv import load_dotenv
    load_dotenv()

    # è¿è¡Œä¸»ç¨‹åº
    asyncio.run(main())